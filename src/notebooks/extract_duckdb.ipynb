{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import duckdb\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Setting pandas to display all columns and rows\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API key from .env file\n",
    "api_key = os.getenv('API_KEY')\n",
    "\n",
    "def extract(api_key):\n",
    "    \"\"\"\n",
    "    Fetch and process air quality measurements from the OpenAQ API.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    api_key : str\n",
    "        API key for authentication with the OpenAQ API.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas.DataFrame or None\n",
    "        Dataframe containing the fetched measurements, or None if no data is fetched.\n",
    "    \"\"\"\n",
    "    \n",
    "    # API URL\n",
    "    api_url = \"https://api.openaq.org/v2/measurements\"\n",
    "    \n",
    "    # Define the query parameters to API\n",
    "    params = {\n",
    "        \"location_id\": \"380422\",\n",
    "        \"parameter\": [\"pressure\", \"temperature\", \"um003\", \"um025\", \"um010\", \"pm10\", \"um100\", \"pm1\", \"um005\", \"humidity\", \"um050\", \"pm25\"],\n",
    "        \"limit\": 9000,\n",
    "        \"api_key\": api_key\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Make the GET request\n",
    "        response = requests.get(api_url, params=params, timeout=30)\n",
    "        response.raise_for_status()  # Raise exception for HTTP errors\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            output = pd.json_normalize(data['results'])\n",
    "            df = pd.DataFrame(output)\n",
    "            \n",
    "            if df.empty:\n",
    "                print(\"Extracted dataframe is empty. No data to load.\")\n",
    "                return None\n",
    "\n",
    "            df['date.utc'] = pd.to_datetime(df['date.utc'], errors='coerce')\n",
    "            df['date.local'] = df['date.utc'].dt.tz_convert('America/Los_Angeles')\n",
    "            df['date.local'] = df['date.local'].dt.tz_localize(None)\n",
    "            df = df[df['value'] > 0.0]\n",
    "            \n",
    "            return df\n",
    "\n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        print(\"Http Error:\", errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        print(\"Error Connecting:\", errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        print(\"Timeout Error:\", errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        print(\"Error: Something Else\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7971 entries, 0 to 8999\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype              \n",
      "---  ------                 --------------  -----              \n",
      " 0   locationId             7971 non-null   int64              \n",
      " 1   location               7971 non-null   object             \n",
      " 2   parameter              7971 non-null   object             \n",
      " 3   value                  7971 non-null   float64            \n",
      " 4   unit                   7971 non-null   object             \n",
      " 5   country                7971 non-null   object             \n",
      " 6   city                   0 non-null      object             \n",
      " 7   isMobile               7971 non-null   bool               \n",
      " 8   isAnalysis             0 non-null      object             \n",
      " 9   entity                 7971 non-null   object             \n",
      " 10  sensorType             7971 non-null   object             \n",
      " 11  date.utc               7971 non-null   datetime64[ns, UTC]\n",
      " 12  date.local             7971 non-null   datetime64[ns]     \n",
      " 13  coordinates.latitude   7971 non-null   float64            \n",
      " 14  coordinates.longitude  7971 non-null   float64            \n",
      "dtypes: bool(1), datetime64[ns, UTC](1), datetime64[ns](1), float64(3), int64(1), object(8)\n",
      "memory usage: 941.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Call extract function\n",
    "df = extract(api_key)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ale\\Documents\\Data-Science-Projects\\Ploomber-2023\\ETL-pipeline-ML\\src\\notebooks\n",
      "c:\\Users\\Ale\\Documents\\Data-Science-Projects\\Ploomber-2023\\ETL-pipeline-ML\\src\n",
      "c:\\Users\\Ale\\Documents\\Data-Science-Projects\\Ploomber-2023\\ETL-pipeline-ML\\src\\data\n"
     ]
    }
   ],
   "source": [
    "# Define current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(current_dir)\n",
    "\n",
    "# Get parent directory\n",
    "parent_directory = os.path.dirname(current_dir)\n",
    "print(parent_directory)\n",
    "\n",
    "# Define directory to store DuckDB database\n",
    "database_directory = os.path.join(parent_directory, \"data\")\n",
    "print(database_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define table name\n",
    "table_name = \"air_data\"\n",
    "\n",
    "# Create local DuckDB instance\n",
    "def init_duckdb(df, table_name, database_directory):\n",
    "    \"\"\"\n",
    "    Initiate a DuckDB instance to create a DuckDB database named \"air_data.duckdb\" inside the\n",
    "    given `database_directory` if it does not already exist. If the specified `table_name`\n",
    "    does not exist in the database, it will be created and the given DataFrame `df`\n",
    "    will be stored in it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame to be registered and stored in the DuckDB database.\n",
    "    table_name : str\n",
    "        Name of the table in which the DataFrame should be stored.\n",
    "    database_directory : str\n",
    "        Directory path where the DuckDB database file (\"air_data.duckdb\") will be located.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "\n",
    "    \"\"\"\n",
    "    duckdb_directory = os.path.join(database_directory, \"air_data.duckdb\")\n",
    "    con = duckdb.connect(duckdb_directory)\n",
    "    con.register('df', df)\n",
    "    \n",
    "    # Check if table already exists, if not, create it\n",
    "    tables = con.execute(\"SHOW TABLES\").fetchall()\n",
    "    if table_name not in [table[0] for table in tables]:\n",
    "        con.execute(f\"CREATE TABLE {table_name} AS SELECT * FROM df\")\n",
    "    \n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call init_duckdb function to create a local DuckDB database\n",
    "init_duckdb(df, table_name, database_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MotherDuck token\n",
    "md_token = os.getenv('MOTHERDUCK_TOKEN')\n",
    "\n",
    "def load_into_motherduck(df, md_token):\n",
    "    \"\"\"\n",
    "    Load data from a pandas DataFrame into MotherDuck.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame or None\n",
    "        DataFrame to be loaded into MotherDuck. If None, nothing is loaded.\n",
    "    md_token : str\n",
    "        The MotherDuck token.\n",
    "    \"\"\"\n",
    "\n",
    "    if df is None:\n",
    "        print(\"No data to load into MotherDuck.\")\n",
    "        return\n",
    "    \n",
    "    # Assert that 'md_token' is neither None nor empty, else raise an AssertionError.\n",
    "    assert md_token and md_token.strip() != '', \"MOTHERDUCK_TOKEN is not set or is empty.\"\n",
    "\n",
    "    # Connect to MotherDuck database\n",
    "    motherduck_con = duckdb.connect(f'md:?motherduck_token={md_token}')\n",
    "    \n",
    "    # Load the MotherDuck module.\n",
    "    motherduck_con.execute(\"LOAD motherduck\")\n",
    "    \n",
    "    # Uploads pandas datafarme into  MotherDuck database.\n",
    "    motherduck_con.execute(\"CREATE OR REPLACE TABLE openaq_api.main.df as SELECT * FROM 'df'\")\n",
    "    \n",
    "    # Close connection after dataframe is uploaded\n",
    "    motherduck_con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call load_into_motherduck function\n",
    "load_into_motherduck(df, md_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Query local air_data.duckdb database\n",
    "# duckdb_df = duckdb.sql(\"SELECT * FROM df\").df()\n",
    "# duckdb_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automate-etl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
